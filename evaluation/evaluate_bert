parser = argparse.ArgumentParser()
parser.add_argument("--corpus_eval")
parser.add_argument("--block_size", type = int)
parser.add_argument("--model_name_or_path")
parser.add_argument("--token_vocab", default = '/home/ubuntu/lrz_share/data/token_vocab/bert/')
args = parser.parse_args()

import torch
from transformers import BertTokenizerFast
tokenizer = BertTokenizerFast.from_pretrained(args.token_vocab)

from transformers import BertForPreTraining
model = BertForPreTraining.from_pretrained(args.model_name_or_path)

from transformers import TextDatasetForNextSentencePrediction
data_eval = TextDatasetForNextSentencePrediction(
    tokenizer = tokenizer,
    file_path = args.corpus_eval, 
    block_size = args.block_size,
)

from transformers import DataCollatorForNextSentencePrediction
data_collator = DataCollatorForNextSentencePrediction(
    tokenizer = tokenizer, 
    mlm = True, 
    mlm_probability = 0.15,
    block_size = args.block_size
)

from transformers import Trainer
trainer = Trainer(
    model=model,
    data_collator=data_collator,
    eval_dataset=data_eval,
    prediction_loss_only=True
)

eval_loss = trainer.evaluate().get('eval_loss')
